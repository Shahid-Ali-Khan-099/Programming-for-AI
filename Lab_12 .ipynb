{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis (Text Classification)**\n",
        "*   **Downloading Datset from Kaggle to Google Colab**\n",
        "*   **Text Cleaning**\n",
        "*   **Text Preprocessing**\n",
        "*   **Feature Engineering**\n",
        "*   **ML Model**"
      ],
      "metadata": {
        "id": "QKxILf5ndoUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmKnCfBodcue",
        "outputId": "a7e6e3b9-9454-4335-fd38-8ee6edc7281a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
            "License(s): other\n",
            "imdb-dataset-of-50k-movie-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  imdb-dataset-of-50k-movie-reviews.zip\n",
            "replace IMDB Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "!pip install kaggle\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Set up Kaggle API credentials\n",
        "#os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "#/content/kaggle.json\n",
        "# Make the Kaggle API key available to the environment\n",
        "with open('/content/kaggle.json') as f:\n",
        "    kaggle_json = json.load(f)\n",
        "    os.environ['KAGGLE_USERNAME'] = kaggle_json['username']\n",
        "    os.environ['KAGGLE_KEY'] = kaggle_json['key']\n",
        "\n",
        "#!/bin/bash\n",
        "!kaggle datasets download lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "\n",
        "!unzip imdb-dataset-of-50k-movie-reviews.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Preprocessing Libraries**"
      ],
      "metadata": {
        "id": "Opp1GMraebjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "stopwords.words('english')\n",
        "exclude = string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5-bcmcNee4l",
        "outputId": "01196d9e-6754-4a9e-c72f-b210de464e75"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading Data**"
      ],
      "metadata": {
        "id": "A4QQYCBbeonO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "df = temp_df.iloc[:30000]"
      ],
      "metadata": {
        "id": "IT9OMIfMe0jm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Cleaning & Preprocessing**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KkZ1tUgelQgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html_tags(text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "def remove_url(text):\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "#exclude = \"!.,?\"\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', exclude))"
      ],
      "metadata": {
        "id": "1pKTCdM-e9ul"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].str.lower()\n",
        "\n",
        "df['review'] = df['review'].apply(remove_html_tags)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_url)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_punc)\n",
        "\n",
        "#df['review'] = df['review'].apply(word_tokenize)\n",
        "\n",
        "#df['review'] = df['review'].apply(remove_stopwords)\n",
        "\n",
        "#df['review'] = df['review'].apply(lemmatize_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMJGFEx7kbKF",
        "outputId": "d77f41cb-a7b0-4607-de32-3f2bc4485f8e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-6f636dc7a57c>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].str.lower()\n",
            "<ipython-input-21-6f636dc7a57c>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_html_tags)\n",
            "<ipython-input-21-6f636dc7a57c>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_url)\n",
            "<ipython-input-21-6f636dc7a57c>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_punc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "zV6bPViYl3_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target Column Encoding**"
      ],
      "metadata": {
        "id": "JJozhru2MDY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#X = df.drop('sentiment', axis=1)\n",
        "X = df['review']\n",
        "Y = df['sentiment']\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y)\n",
        "\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuTETTE2Retv",
        "outputId": "ba786a04-43e3-49b6-d840-38edd7273e4a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        one of the other reviewers has mentioned that ...\n",
            "1        a wonderful little production the filming tech...\n",
            "2        i thought this was a wonderful way to spend ti...\n",
            "3        basically theres a family where a little boy j...\n",
            "4        petter matteis love in the time of money is a ...\n",
            "                               ...                        \n",
            "29995    new york i love you finally makes it to our sh...\n",
            "29996    this movie makes you wish imdb would let you v...\n",
            "29997    space camp which had the unfortunate luck to b...\n",
            "29998    octavio paz mexican poet writer and diplomat w...\n",
            "29999    having watched 10 minutes of this movie i was ...\n",
            "Name: review, Length: 30000, dtype: object\n",
            "0        positive\n",
            "1        positive\n",
            "2        positive\n",
            "3        negative\n",
            "4        positive\n",
            "           ...   \n",
            "29995    positive\n",
            "29996    negative\n",
            "29997    negative\n",
            "29998    positive\n",
            "29999    negative\n",
            "Name: sentiment, Length: 30000, dtype: object\n",
            "[1 1 1 ... 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words**"
      ],
      "metadata": {
        "id": "S7enK_qOl9Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "#print(X_train.head)\n",
        "\n",
        "#print(X_train)\n",
        "#print(X_test)\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data and transform it\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_bow.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_bow.shape}\")\n",
        "\n",
        "# Applying Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_bow,y_train)\n",
        "y_pred = rf.predict(X_test_bow)\n",
        "#accuracy_score(y_test,y_pred)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu52GS7sSEbM",
        "outputId": "ef8705dd-80d5-48bb-9b9b-a845c26e7db7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24000,)\n",
            "Shape of X_train_bow: (24000, 139736)\n",
            "Shape of X_test_bow: (6000, 139736)\n",
            "0.8456666666666667\n",
            "[[2549  480]\n",
            " [ 446 2525]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n-gram (2-gram)**"
      ],
      "metadata": {
        "id": "J1sjksiJMUIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(ngram_range=(2,2))\n",
        "\n",
        "X_train_n_gram = cv.fit_transform(X_train)\n",
        "X_test_n_gram = cv.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_n_gram.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_n_gram.shape}\")\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_n_gram,y_train)\n",
        "y_pred = rf.predict(X_test_n_gram)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m0KGuBSNatZ",
        "outputId": "85b05be7-ac46-4068-d8ac-d9cf3941b394"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_bow: (24000, 1500023)\n",
            "Shape of X_test_bow: (6000, 1500023)\n",
            "0.8305\n",
            "[[2508  521]\n",
            " [ 496 2475]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF/IDF**"
      ],
      "metadata": {
        "id": "4QsY7r2INm7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_tfidf.shape}\")\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_tfidf,y_train)\n",
        "y_pred = rf.predict(X_test_tfidf)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQNLOLLyNr2v",
        "outputId": "a100b783-f932-4c88-c497-54280b1d1315"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_bow: (24000, 139736)\n",
            "Shape of X_test_bow: (6000, 139736)\n",
            "0.8356666666666667\n",
            "[[2539  490]\n",
            " [ 496 2475]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task:**\n",
        "*   **Add a Python Function for Word-based Tokenization for each of the IMDB reviews data.**\n",
        "*   **After tokenization, add a Python Function to remove Stop Words from the IMDB reviews data.**\n",
        "*   **After Stopword Removal, add a Python Function to perform Lemmitization over IMDB Reviews data.**\n",
        "\n",
        "**After applying the above mentioned data preprocessing steps, again run this code and analyse the performance of the ML models for text classification of IMDB Reviews.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xbqQjfUg4PG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading Data**"
      ],
      "metadata": {
        "id": "j-F_0AWAbIcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "df = temp_df.iloc[:30000]"
      ],
      "metadata": {
        "id": "qc7XUJVvZrOx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Cleaning & Preprocessing**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vSFibIYbbGB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove HTML tags\n",
        "def remove_html_tags(text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "# Function to remove URLs\n",
        "def remove_url(text):\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "# Function to remove punctuation\n",
        "def remove_punc(text, exclude=\"!.,?\"):\n",
        "    return text.translate(str.maketrans('', '', exclude))\n",
        "\n",
        "# Function for Word-based Tokenization\n",
        "def tokenize_words(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [word for word in text if word not in stop_words]\n",
        "\n",
        "# Function for Lemmatization\n",
        "def lemmatize_words(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word) for word in text]\n",
        "\n"
      ],
      "metadata": {
        "id": "J_w8CmaoZrkk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply transformations to the review column\n",
        "df['review'] = df['review'].str.lower()  # Convert to lowercase\n",
        "\n",
        "df['review'] = df['review'].apply(remove_html_tags)  # Remove HTML tags\n",
        "df['review'] = df['review'].apply(remove_url)  # Remove URLs\n",
        "df['review'] = df['review'].apply(remove_punc)  # Remove punctuation\n",
        "\n",
        "df['review'] = df['review'].apply(tokenize_words)  # Tokenize words\n",
        "df['review'] = df['review'].apply(remove_stopwords)  # Remove stopwords\n",
        "df['review'] = df['review'].apply(lemmatize_words)  # Lemmatize words\n",
        "\n"
      ],
      "metadata": {
        "id": "gFLfAaEjZrnw",
        "outputId": "df496039-ac74-4960-8f50-182f92a23e3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-5b8b4b7a2040>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].str.lower()  # Convert to lowercase\n",
            "<ipython-input-40-5b8b4b7a2040>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_html_tags)  # Remove HTML tags\n",
            "<ipython-input-40-5b8b4b7a2040>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_url)  # Remove URLs\n",
            "<ipython-input-40-5b8b4b7a2040>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_punc)  # Remove punctuation\n",
            "<ipython-input-40-5b8b4b7a2040>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(tokenize_words)  # Tokenize words\n",
            "<ipython-input-40-5b8b4b7a2040>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_stopwords)  # Remove stopwords\n",
            "<ipython-input-40-5b8b4b7a2040>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(lemmatize_words)  # Lemmatize words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "w2PFf3_Wa6Zd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target Column Encoding**"
      ],
      "metadata": {
        "id": "GKImqJaIapMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#X = df.drop('sentiment', axis=1)\n",
        "X = df['review']\n",
        "Y = df['sentiment']\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y)\n",
        "\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "QEJtpC1lZrrE",
        "outputId": "4d1f972c-44f6-437d-db2d-0c1cf4934307",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [one, reviewer, mentioned, watching, 1, oz, ep...\n",
            "1        [wonderful, little, production, filming, techn...\n",
            "2        [thought, wonderful, way, spend, time, hot, su...\n",
            "3        [basically, 's, family, little, boy, (, jake, ...\n",
            "4        [petter, mattei, 's, ``, love, time, money, ''...\n",
            "                               ...                        \n",
            "29995    [new, york, love, finally, make, shore, 10, sh...\n",
            "29996    [movie, make, wish, imdb, would, let, vote, ze...\n",
            "29997    [space, camp, unfortunate, luck, planned, arou...\n",
            "29998    [octavio, paz, mexican, poet, writer, diplomat...\n",
            "29999    [watched, 10, minute, movie, bewildered, watch...\n",
            "Name: review, Length: 30000, dtype: object\n",
            "0        positive\n",
            "1        positive\n",
            "2        positive\n",
            "3        negative\n",
            "4        positive\n",
            "           ...   \n",
            "29995    positive\n",
            "29996    negative\n",
            "29997    negative\n",
            "29998    positive\n",
            "29999    negative\n",
            "Name: sentiment, Length: 30000, dtype: object\n",
            "[1 1 1 ... 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words**"
      ],
      "metadata": {
        "id": "HiiEaK4Pag17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "#print(X_train.head)\n",
        "\n",
        "#print(X_train)\n",
        "#print(X_test)\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data and transform it\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_bow.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_bow.shape}\")\n",
        "\n",
        "# Applying Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_bow,y_train)\n",
        "y_pred = rf.predict(X_test_bow)\n",
        "#accuracy_score(y_test,y_pred)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "id": "Nb8bm_qyZrud",
        "outputId": "f4eaa42d-1af2-4459-abb7-5c1ba258e45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24000,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'lower'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-73727c244140>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fit the vectorizer on the training data and transform it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX_train_bow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Transform the test data using the same vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1370\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \"\"\"\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Ensure X and Y are properly defined before this\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert lists of tokens back to strings if necessary\n",
        "X_train = [' '.join(text) if isinstance(text, list) else str(text) for text in X_train]\n",
        "X_test = [' '.join(text) if isinstance(text, list) else str(text) for text in X_test]\n",
        "\n",
        "print(X_train[:5])  # Preview the cleaned training data\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data and transform it\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_bow.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_bow.shape}\")\n",
        "\n",
        "# Apply Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_bow, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf.predict(X_test_bow)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "VYjKIRuEgluY",
        "outputId": "aab2d2d4-c060-4f52-8af6-48dcb85f45b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"ever sit movie 's 's like one big `` wtf '' welcome decoy another straight video action fodder flick immediately forget watched better yet n't watch peter weller robert patrick star quickly wasted going nowhere fast mercenaries-for-hire action dud story pretty darn bad action suck 's point watching action flick action blow robert patrick particular hit new low action sequence firing machine gun standing hood moving school bus co-star ambient charlotte lewis canada 's scott hylands ( tv 's night heat fame )\", \"ok bought film woolworth friend joke present birthday front cover sexual innuendo itbut decided watch anyway hilarity purposesand 'm sorry got one worst film historyit began alright thought `` ok might actually ok '' 10 minute sadly mistakenit began `` mysterious paint baller '' turned obvious character scouser/australian ( say accent could n't identified ) 's acting might say abysmalthen got end time lost live paint ball finalsthe thing like plot n't actually win annoyingly enough defaultand know nothing name team given awful critical damage mean could picked awesome name like `` destroyer anti-christ '' something 's film called anyway\", \"hilary great julie pat magnificent mr miyagi reference towards three movie mean come first 's daniel miyagi make brief mention 's daniel best friend 've least made appearance movie could 've helped miyagi train julie-san flip side music stayed true movie though little instrumentation ( fretless bass ) accompany wonderfully played pan-flute n't feel like karate kid movie unless hear pan-flute thank zamfir overall decent movie though miss noriyuki\", \"2:37 high school student commits suicide shown taken life reason known time skip back start day follow six separate student ; marcus melody luke steven sarah sean student struggling moral dilemma reaching boiling point hitting end oneafter losing friend suicide surviving suicide attempt writer/director murali k thalluri created revetting drama focusing teen life horrible act suicide suicide topic kept shadow 2:37 thalluri 's attempt bring light touched act suicide anyone 2:37 becomes harder viewwith heavy hard subject matter thalluri also tackle everyday teenage life crisis 's sex pregnancy sexual identity bullying friendship thalluri manages show extremely realistic manner factor thalluri 's talent subtlety respect subject problem everyone suffered sometime verge near documentary time painful realism ; interview character spliced film heightens this2:37 distinctive similarity gu van sants film elephant core film different tackle teen life like sant thalluri utilizes long tracking shot time skipping back forth show character interaction different perspective defining point elephant ethereal ambiance spare conversation little development character long tracking shot sant created haunting mesmerizing atmosphere coming dread resides dread 2:37 emotional connection character reach higher level sant could n't reach time go character fragility creep dragging along emotional roller-coasterthe real hit film come inevitable suicide foretold beginning hard part scene complete intrusion discomfort audience watching someone life end gruesome fashion though many film shown suicide gloss act romanticizes act thalluri show pain agony involved act best solution unknown lead first major role ; teresa palmereach frank sweet joel mackenzie marni spillane charles baird sam harris show immense talent promising acting careerscompelling revetting 2:37 absolutely unmissable film\", \"film reappeared channel 13 1990s series comedy hollywood 1930s 1940s fact tune `` jolly fat policeman '' montage scene film introduce series people laughing including one gary cooper chortling watching film movie house - sequence filmit begin innocently enough cooper millionaire go fancy department store france buy pajama like sleep top clerk ( tyler brooke ) insists sell half pair pajama cooper want claudette colbert hears argument offer help - like sleep pajama bottom brooke sell half brooke never offer go floor walker ( rolfe sedan ) asks done disturbed - request quite unconventional eventually contact store 's owner ( charles halton ) halton bed get - skinny frame supporting pajama top ( suitably long one sake censorship ) sell two customer one set pajama ( half ) properly horrified halton answer `` course communism '' sale allowed apparently nobody think cooper buy total pair sell half colbertlubitsch 's bluebeard 's eighth wife reputation falling flat viewer liking misreading colbert 's character seen quite mercenary towards cooper - selling termsactually cooper 's character nastier rich figure everything price correct time look way colbert 's aristocratic pauper father edward everett horton see new son-in-law golden goose use cooper 's willingness marry colbert somehow includes agreement hesitant chooses marry pay damage horton realizes take watch ( reassuring voice ) say cooper - `` take time boy '' come decision later see horton 's wardrobe gotten modern fancierthe film script billy wilder charles brackett compare well script mitchell leisin 's midnight ( also colbert ameche john barrymore ) colbert willing sell money marriage ( francis lederer ) complicated fictitious marriage ameche really love ameche ( taxi driver ) explains unexpectedly realistic moment parent married `` love '' poverty made grow hate found bluebeard 's eighth wife colbert background like ( daughter marquis ) mercenary plotting teach cooper lesson standardsthe film nice work supporting staff including herman bing private eye turn hiding thing colbert learns young david niven set choice moment stand punching bag willing ear cooper coop tell niven problem colbert infuriating niven listens respectfully end cooper touched willingness hear say `` albert much pay '' cooper asks niven think say `` thirty five franc week sir '' cooper look deeply soul say ( shaking head ) `` 's fair ''\"]\n",
            "Shape of X_train_bow: (24000, 105046)\n",
            "Shape of X_test_bow: (6000, 105046)\n",
            "Accuracy: 0.8483333333333334\n",
            "Confusion Matrix:\n",
            " [[2579  450]\n",
            " [ 460 2511]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n-gram (2-gram)**"
      ],
      "metadata": {
        "id": "7J9L9OWeaJ4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(ngram_range=(2,2))\n",
        "\n",
        "X_train_n_gram = cv.fit_transform(X_train)\n",
        "X_test_n_gram = cv.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_n_gram.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_n_gram.shape}\")\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_n_gram,y_train)\n",
        "y_pred = rf.predict(X_test_n_gram)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "id": "P135Xtp2Zrx2",
        "outputId": "a0f712a5-04bc-4f3e-bbfd-3d9f2896d258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_bow: (24000, 1676542)\n",
            "Shape of X_test_bow: (6000, 1676542)\n",
            "0.7893333333333333\n",
            "[[2151  878]\n",
            " [ 386 2585]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF/IDF**"
      ],
      "metadata": {
        "id": "L_511VSeaQPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_tfidf.shape}\")\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_tfidf,y_train)\n",
        "y_pred = rf.predict(X_test_tfidf)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "id": "qbmGSPpfZr1D",
        "outputId": "74a9d783-ef1d-4497-a035-19942706fcbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_bow: (24000, 105046)\n",
            "Shape of X_test_bow: (6000, 105046)\n",
            "0.8508333333333333\n",
            "[[2589  440]\n",
            " [ 455 2516]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VVPV3_CNlM5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}